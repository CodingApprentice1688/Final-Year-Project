{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e5aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bb8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate face detection on 5 Celebrity Faces Dataset\n",
    "from os import listdir\n",
    "def extract_face(filename, required_size=(200, 200)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    image = image.convert('RGB')\n",
    "    pixels = asarray(image)\n",
    "    # use MTCNN face detector to detect faces inside the image\n",
    "    detector = MTCNN()\n",
    "    results = detector.detect_faces(pixels)\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    # bug fix\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff3afa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m     pyplot\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mcheck_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mcheck_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# enumerate files\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlistdir\u001b[49m(folder):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# path\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     path \u001b[38;5;241m=\u001b[39m folder \u001b[38;5;241m+\u001b[39m filename\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# get face\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'listdir' is not defined"
     ]
    }
   ],
   "source": [
    "# specify folder to plot\n",
    "def check_images():\n",
    "    folder = '..\\FYP\\deeplearning\\train\\wenling'\n",
    "    i = 1\n",
    "    # enumerate files\n",
    "    for filename in listdir(folder):\n",
    "        # path\n",
    "        path = folder + filename\n",
    "        # get face\n",
    "        face = extract_face(path)\n",
    "        print(i, face.shape)\n",
    "        # plot\n",
    "        pyplot.subplot(2, 7, i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(face)\n",
    "        i += 1\n",
    "    pyplot.show()\n",
    "\n",
    "check_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3105e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_train_test_dataset(path):\n",
    "    data = []\n",
    "    label = []\n",
    "    directorii = []\n",
    "    i = 0\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        if i == 0:\n",
    "            directorii = dirs\n",
    "        i = 1\n",
    "\n",
    "    x = 1\n",
    "    for i in directorii:\n",
    "        img_path = os.path.join(path, str(i)) \n",
    "        print(img_path)\n",
    "        for img in os.listdir(img_path):\n",
    "            image = extract_face(img_path + '/' + img)\n",
    "            images = image.astype('float32')\n",
    "            images = np.array(images)\n",
    "\n",
    "\n",
    "            data.append(images)\n",
    "            label.append(i)\n",
    "\n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "\n",
    "    print(\"success\")\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dfe4d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading train images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mobtain_train_test_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mFYP\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdeeplearning\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading test images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m obtain_train_test_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFYP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdeeplearning\u001b[39m\u001b[38;5;130;01m\\v\u001b[39;00m\u001b[38;5;124mal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mobtain_train_test_dataset\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m directorii \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subdir, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mwalk(path):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      8\u001b[0m         directorii \u001b[38;5;241m=\u001b[39m dirs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Reading train images\")\n",
    "x_train, y_train = obtain_train_test_dataset(\"..\\FYP\\deeplearning\\train\")\n",
    "print(\"Reading test images\")\n",
    "x_test, y_test = obtain_train_test_dataset(\"..\\FYP\\deeplearning\\val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f3a499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7addb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from tensorflow import keras\n",
    "\n",
    "# def get_model():\n",
    "#     model = Sequential()\n",
    "#     #apply transfer learning using ResNet50\n",
    "# #     model.add(keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(200, 200, 3)))\n",
    "# #     model.add(Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\"))\n",
    "# #     model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# #     model.add(Dropout(rate=0.25))\n",
    "# #     model.add(keras.layers.Flatten())\n",
    "\n",
    "# #     model.add(Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "#     model.add(Conv2D(2048, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
    "#     model.add(MaxPool2D((2, 2)))\n",
    "#     model.add(Conv2D(2048, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPool2D((2, 2)))\n",
    "#     model.add(Conv2D(1024, (3, 3), activation='relu'))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(6))\n",
    "\n",
    "#     model.layers[0].trainable=False\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf31e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    #apply transfer learning using ResNet50\n",
    "    model.add(keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(200, 200, 3)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "    model.layers[0].trainable=False\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71b15a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = get_model()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aafd023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " flatten_292 (Flatten)       (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1017 (Dense)          (None, 6)                 12294     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_compiled_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d85679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 9s 4s/step - loss: 2.0874 - accuracy: 0.1538 - val_loss: 1.7018 - val_accuracy: 0.2667\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 1.7753 - accuracy: 0.2885 - val_loss: 1.5596 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 1.6135 - accuracy: 0.4038 - val_loss: 1.3981 - val_accuracy: 0.4333\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 1.3764 - accuracy: 0.4904 - val_loss: 1.1949 - val_accuracy: 0.4667\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 1.2443 - accuracy: 0.5192 - val_loss: 1.0078 - val_accuracy: 0.7333\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 1.0445 - accuracy: 0.6250 - val_loss: 0.8617 - val_accuracy: 0.7667\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.9151 - accuracy: 0.6827 - val_loss: 0.7436 - val_accuracy: 0.7667\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.8176 - accuracy: 0.7692 - val_loss: 0.6625 - val_accuracy: 0.8333\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.7300 - accuracy: 0.7885 - val_loss: 0.6033 - val_accuracy: 0.8333\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.6584 - accuracy: 0.7500 - val_loss: 0.5593 - val_accuracy: 0.9000\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.5320 - accuracy: 0.8558 - val_loss: 0.5241 - val_accuracy: 0.8667\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.4524 - accuracy: 0.9038 - val_loss: 0.4897 - val_accuracy: 0.8333\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.4419 - accuracy: 0.8942 - val_loss: 0.4576 - val_accuracy: 0.8333\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.4318 - accuracy: 0.8942 - val_loss: 0.4348 - val_accuracy: 0.8667\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.3874 - accuracy: 0.9038 - val_loss: 0.4064 - val_accuracy: 0.9000\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.3186 - accuracy: 0.9519 - val_loss: 0.3749 - val_accuracy: 0.9333\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.3193 - accuracy: 0.9519 - val_loss: 0.3436 - val_accuracy: 0.9667\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2890 - accuracy: 0.9519 - val_loss: 0.3184 - val_accuracy: 0.9667\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2692 - accuracy: 0.9615 - val_loss: 0.3041 - val_accuracy: 0.9667\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2486 - accuracy: 0.9712 - val_loss: 0.2958 - val_accuracy: 0.9667\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2226 - accuracy: 0.9519 - val_loss: 0.2912 - val_accuracy: 0.9667\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2410 - accuracy: 0.9712 - val_loss: 0.2912 - val_accuracy: 0.9333\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.1836 - accuracy: 0.9808 - val_loss: 0.2889 - val_accuracy: 0.9333\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.1657 - accuracy: 0.9904 - val_loss: 0.2804 - val_accuracy: 0.9333\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.1509 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9333\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.1520 - accuracy: 0.9808 - val_loss: 0.2589 - val_accuracy: 0.9333\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.1806 - accuracy: 0.9615 - val_loss: 0.2461 - val_accuracy: 0.9667\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.1374 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9667\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.1561 - accuracy: 0.9808 - val_loss: 0.2408 - val_accuracy: 0.9667\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.1206 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9333\n",
      "Test Set Accuracy: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    model = get_compiled_model()\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=30, batch_size=64, validation_data=(x_test, y_test),\n",
    "                       callbacks=[callback])\n",
    "    [loss, acc] = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    print(\"Test Set Accuracy: \" + str(acc))\n",
    "    return model\n",
    "    \n",
    "model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_modelv3.h5\") #using h5 extension\n",
    "print(\"model saved!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d0b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
