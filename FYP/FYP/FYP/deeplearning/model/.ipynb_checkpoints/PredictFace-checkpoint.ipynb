{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290554e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read() #read one frame\n",
    "cap.release()\n",
    "cv2.imshow('image', frame)\n",
    "cv2.imwrite(\"framed.jpg\", frame)  \n",
    "if cv2.waitKey(0) & 0xff == ord('q'): # press q to exit\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a5d2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " flatten_291 (Flatten)       (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1016 (Dense)          (None, 6)                 12294     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('my_modelv3.h5')\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "328e7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate face detection on 5 Celebrity Faces Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from mtcnn import MTCNN\n",
    "from os import listdir\n",
    "\n",
    "def extract_face(filename, required_size=(200, 200)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    image = image.convert('RGB')\n",
    "    pixels = asarray(image)\n",
    "    # use MTCNN face detector to detect faces inside the image\n",
    "    detector = MTCNN()\n",
    "    results = detector.detect_faces(pixels)\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    # bug fix\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bfded12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pixels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_face\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Desktop/framed.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m hello \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m pyplot\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_face' is not defined"
     ]
    }
   ],
   "source": [
    "pixels = extract_face('../Desktop/framed.jpg')\n",
    "hello = []\n",
    "pyplot.subplot(2, 7, 1)\n",
    "pyplot.axis('off')\n",
    "pyplot.imshow(pixels)\n",
    "pyplot.show()\n",
    "pixels = pixels.astype('float32')\n",
    "pixels = np.array(pixels)\n",
    "hello.append(pixels)\n",
    "hello = np.array(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2da317b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction shape: [[0.2885074  0.46903995 0.03692678 0.17537315 0.00256144 0.02759128]]\n"
     ]
    }
   ],
   "source": [
    "yhat=model.predict(hello)\n",
    "print(\"prediction shape:\", yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65ad6cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3768858039.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [5]\u001b[1;36m\u001b[0m\n\u001b[1;33m    for subdir, dirs, files in os.walk(\"C:\\Users\\leong\\source\\repos\\csci321_fyp\\FYP\\FYP\\FYP\\deeplearning\\val\"):\u001b[0m\n\u001b[1;37m                                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = []\n",
    "i = 0\n",
    "for subdir, dirs, files in os.walk(\"../Desktop/celeb/val\"):\n",
    "    if i == 0:\n",
    "        y_test = dirs\n",
    "    i = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3999937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is: jonathandoe\n"
     ]
    }
   ],
   "source": [
    "prediction_index = np.argmax(yhat, axis=None, out=None)\n",
    "prediction = y_test[prediction_index]\n",
    "\n",
    "print(\"The person is: \" + prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd028dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
